{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1547f22f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T05:45:29.057317Z",
     "start_time": "2025-04-21T05:45:29.039024Z"
    }
   },
   "source": [
    "# Stock Analysis Assistant (Adaptive RAG)\n",
    "\n",
    "Welcome to the **Stock Analysis Assistant**, an intelligent application that combines Retrieval-Augmented Generation (RAG) with real-time web and financial data.\n",
    "\n",
    "## What it does:\n",
    "- Answers stock-related queries using both **internal company data** and **real-time news & sentiment**\n",
    "- Uses **adaptive RAG** to decide whether to search web sources\n",
    "- Supports natural language questions like:\n",
    "  - *\"What does Nvidia do and when are its earnings?\"*\n",
    "  - *\"Any recent news on Tesla?\"*\n",
    "  - *\"Summarize Apple's financial performance and market sentiment.\"*\n",
    "\n",
    "---\n",
    "\n",
    "## Tech Stack:\n",
    "- **LangChain + Mistral/Groq** – For LLM-based Q&A\n",
    "- **ChromaDB** – Internal vector store containing all listed companies' overview\n",
    "- **HuggingFace Embeddings** – For semantic retrieval\n",
    "- **Hugging Face Hub** – For storing the vector database (cloud-based persistence)\n",
    "- **Tavily API** – For real-time web search (news, sentiment, etc.)\n",
    "- **Alpha Vantage API** *(optional)* – For structured financial data\n",
    "- **LangSmith** – Observability, tracing, and debugging\n",
    "- **Streamlit (Planned)** – To deploy an interactive web app\n",
    "\n",
    "---\n",
    "##  Key Features:\n",
    "- **Query rewriting & multi-query expansion** to improve retrieval\n",
    "- **Fusion of internal + web results** with semantic reranking\n",
    "- **Adaptive logic** to trigger web search only when needed\n",
    "- **LangSmith Tracing** for full pipeline observability\n",
    "\n",
    "---\n",
    "\n",
    "## Storage & Deployment:\n",
    "- Vector DB stored on **Hugging Face Hub**\n",
    "- Planned deployment using **Streamlit** for live demos\n",
    "\n",
    "---\n",
    "\n",
    "## Potential Areas for Improvement:\n",
    "- **Better routing** for information retrieval for different question types.\n",
    "- **Structured Answers** based on the questions' classification i.e. Fundamental Analysis/Technical Analysis/News Sentiment.\n",
    "- Add **cross-encoder re-ranking** to improve document relevance\n",
    "- Create an **evaluation dataset** for quantitative benchmarking\n",
    "- Integrate **financial charts or visualizations**\n",
    "- Add **agentic capabilities** for multi-step queries\n",
    "- Implement **user feedback loop** for adaptive learning\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "> This project showcases an end-to-end RAG pipeline with real-time web and financial data — optimized for clarity, performance, and interactivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df9cdb7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T09:03:03.300574Z",
     "start_time": "2025-04-21T09:03:00.426317Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install langchain_groq langsmith alpha_vantage\n",
    "!pip install -U langchain-huggingface langchain-chroma\n",
    "!pip install -U langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c625c86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T09:03:03.688903Z",
     "start_time": "2025-04-21T09:03:03.303377Z"
    }
   },
   "outputs": [],
   "source": [
    "#LangSmith Tracing\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # Loads from .env file\n",
    "\n",
    "\n",
    "from langsmith import  Client\n",
    "from langchain_core.runnables import RunnableLambda, RunnableSequence\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"stock-analysis rag project\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4765a074",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T09:03:04.433072Z",
     "start_time": "2025-04-21T09:03:03.689709Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Tavily and alpha_vantage API Key ---\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "from alpha_vantage.fundamentaldata import FundamentalData\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"] = os.getenv(\"TAVILY_API_KEY\")\n",
    "os.environ[\"ALPHA_VANTAGE_API_KEY\"] = os.getenv(\"ALPHA_VANTAGE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52fefd80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T09:27:09.663279Z",
     "start_time": "2025-04-21T09:27:00.707590Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f20355b014a4eccbf52e8793e9478bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "692a5dfcbfdd46e39ea11e8f05f4327f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/2.46k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bf07335ae404134a018adda1af1e34b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "company_vectors.zip:   0%|          | 0.00/72.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# --- Embeddings + Vector Store ---\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings  \n",
    "from langchain_chroma import Chroma \n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def load_vectorstore():\n",
    "    # Download company_vectors dataset from HuggingFace\n",
    "    dataset_path = snapshot_download(\n",
    "        repo_id=\"gargumang411/company_vectors\",\n",
    "        repo_type=\"dataset\",\n",
    "        cache_dir=\"./company_vectors_cache\"\n",
    "    )\n",
    "    embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "    return Chroma(\n",
    "        persist_directory=dataset_path,\n",
    "        embedding_function=embedding_model\n",
    "    )\n",
    "\n",
    "# Initialize vectorstore\n",
    "vectorstore = load_vectorstore()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed95164d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T09:03:10.378558Z",
     "start_time": "2025-04-21T09:03:10.217306Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# --- LLM ---\n",
    "from langchain_groq import ChatGroq\n",
    "# from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama3-70b-8192\",  # or \"mistral-7b\"\n",
    "    temperature=0,\n",
    "    groq_api_key= os.getenv(\"GROQ_API_KEY\")\n",
    ")\n",
    "\n",
    "# --- LangSmith Client ---\n",
    "ls_client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef8f16e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T09:03:10.381923Z",
     "start_time": "2025-04-21T09:03:10.379600Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Prompt Templates ---\n",
    "qa_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are a financial assistant. Below is the context, including intermediate steps (query variants, retrieved documents, summaries) from web sources, a company database, and Alpha Vantage API. Answer the user's question clearly and concisely, citing sources (Company DB, Web, Alpha Vantage) where relevant. For news queries, prioritize recent events (e.g., 2025). For analysis queries, include key financial metrics (e.g., P/E, EPS, revenue) if available. If data is limited, provide a general response.\n",
    "\n",
    "Intermediate Steps:\n",
    "- Query Variants: {query_variants}\n",
    "- Retrieved Documents: {doc_summaries}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\")\n",
    "\n",
    "summarize_prompt = PromptTemplate.from_template(\"\"\"\n",
    "Summarize the following financial document to ~200 words, focusing on recent news, financial metrics (e.g., P/E, EPS, revenue), or analyst recommendations. Exclude irrelevant details (e.g., ads, unrelated companies):\n",
    "\n",
    "{document}\n",
    "Summary:\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "852df2a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T09:03:10.404987Z",
     "start_time": "2025-04-21T09:03:10.383064Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List, Dict, Tuple\n",
    "from langchain.schema import Document\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "# --- Query Cleaning ---\n",
    "def clean_query(query: str) -> str:\n",
    "    query = re.sub(r'[^\\w\\s\\-\\.]', '', query)  # Remove special characters\n",
    "    query = \" \".join(query.split()[:20])  # Limit to 20 words\n",
    "    return query.strip()\n",
    "\n",
    "# --- Ticker Map ---\n",
    "def build_ticker_map(vectorstore) -> Dict[str, str]:\n",
    "    ticker_map = {}\n",
    "    docs = vectorstore.get()\n",
    "    for metadata in docs.get(\"metadatas\", []):\n",
    "        if metadata.get(\"ticker\") and metadata.get(\"company_name\"):\n",
    "            ticker_map[metadata[\"company_name\"].lower()] = metadata[\"ticker\"]\n",
    "    return ticker_map\n",
    "\n",
    "# --- Ticker Extraction ---\n",
    "def extract_ticker(query: str, vectorstore, ticker_map: Dict[str, str]) -> str:\n",
    "    query_lower = query.lower()\n",
    "    for company, ticker in ticker_map.items():\n",
    "        if company in query_lower:\n",
    "            return ticker\n",
    "    search_results = vectorstore.similarity_search(query, k=1)\n",
    "    if search_results and \"ticker\" in search_results[0].metadata:\n",
    "        return search_results[0].metadata[\"ticker\"]\n",
    "    prompt = f\"Extract the stock ticker from this query, return only the ticker symbol or 'TSLA' if unclear:\\n\\\"{query}\\\"\"\n",
    "    return llm.invoke(prompt).content.strip()\n",
    "\n",
    "\n",
    "extract_ticker_lambda = RunnableLambda(\n",
    "\n",
    "    lambda inputs: extract_ticker(inputs[\"query\"], inputs[\"vectorstore\"], inputs[\"ticker_map\"])\n",
    "\n",
    ")\n",
    "# --- Query Rewriting ---\n",
    "def translate_query(query: str, ticker: str ) -> str:\n",
    "    prompt = f\"\"\"\n",
    "You're optimizing user queries for better retrieval in a stock research assistant.\n",
    "\n",
    "Example:\n",
    "Original: \"any latest news on {ticker}?\"\n",
    "Improved: \"{ticker} latest news 2025 earnings stock performance\"\n",
    "\n",
    "Rewrite the user's query to maximize document retrieval relevance for {ticker}, focusing on financial news or metrics:\n",
    "\\\"{query}\\\"\n",
    "\"\"\"\n",
    "    return clean_query(llm.invoke(prompt).content.strip())\n",
    "\n",
    "\n",
    "translate_query_lambda = RunnableLambda(\n",
    "\n",
    "    lambda inputs: translate_query(inputs[\"query\"], inputs[\"ticker\"])\n",
    "\n",
    ")\n",
    "# --- Multi-query Generation ---\n",
    "def generate_query_variants(query: str, n=2) -> List[str]:\n",
    "    prompt = f\"Generate {n} alternative phrasings for this financial query, focusing on recent news or financial metrics:\\n\\n\\\"{query}\\\"\"\n",
    "    raw = llm.invoke(prompt).content\n",
    "    variants = [clean_query(line.strip(\"-• \").strip()) for line in raw.split(\"\\n\") if line.strip()]\n",
    "    return variants[:n]\n",
    "\n",
    "generate_query_variants_lambda = RunnableLambda(\n",
    "\n",
    "    lambda inputs: generate_query_variants(inputs[\"translated_query\"], n=2)\n",
    "\n",
    ")\n",
    "# --- Query Classification for Web Search - currently always true---\n",
    "# def needs_web_search(query: str) -> bool:\n",
    "#     query_lower = query.lower()\n",
    "    \n",
    "#     # If query is long, assume it's complex and needs web search\n",
    "#     if len(query.split()) > 8:\n",
    "#         return True\n",
    "\n",
    "#     # If it's a basic company overview question, no need for web search\n",
    "#     if query_lower.startswith(\"what does\") and \"do\" in query_lower:\n",
    "#         return False\n",
    "#     if \"company overview\" in query_lower:\n",
    "#         return False\n",
    "    \n",
    "#     return True\n",
    "# @traceable\n",
    "# --- Alpha Vantage Data ---\n",
    "def fetch_alpha_vantage_data(ticker: str) -> Dict:\n",
    "    for attempt in range(2):\n",
    "        try:\n",
    "            ts = TimeSeries(key=os.environ[\"ALPHA_VANTAGE_API_KEY\"], output_format='json')\n",
    "            fd = FundamentalData(key=os.environ[\"ALPHA_VANTAGE_API_KEY\"], output_format='json')\n",
    "            quote_data, _ = ts.get_quote_endpoint(symbol=ticker)\n",
    "            overview, _ = fd.get_company_overview(symbol=ticker)\n",
    "            return {\n",
    "                \"price\": quote_data.get(\"05. price\"),\n",
    "                \"pe_ratio\": overview.get(\"PERatio\"),\n",
    "                \"eps\": overview.get(\"EPS\"),\n",
    "                \"revenue\": overview.get(\"RevenueTTM\"),\n",
    "                \"market_cap\": overview.get(\"MarketCapitalization\")\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Alpha Vantage API call failed for {ticker} (attempt {attempt+1}): {e}\")\n",
    "            if \"rate limit\" in str(e).lower():\n",
    "                time.sleep(5)\n",
    "            else:\n",
    "                time.sleep(1)\n",
    "    return {}\n",
    "\n",
    "fetch_alpha_vantage_lambda = RunnableLambda(\n",
    "\n",
    "    lambda inputs: fetch_alpha_vantage_data(inputs[\"ticker\"])\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# --- Web Search Retrieval ---\n",
    "def retrieve_docs_with_fusion(query: str, ticker: str, av_data: Dict, k=3) -> Tuple[List[Document], List[str], str]:\n",
    "    # --- Vector DB Retrieval ---\n",
    "    internal_docs = []\n",
    "    results = vectorstore.similarity_search_with_score(query, k=2)\n",
    "    for doc, score in results:\n",
    "        internal_docs.append((doc, score + 0.2))\n",
    "\n",
    "    # --- Web Search Retrieval ---\n",
    "    web_docs = []\n",
    "    translated = translate_query(query, ticker)\n",
    "    variants = generate_query_variants(translated, n=2)\n",
    "    all_web_queries = [translated] + variants\n",
    "    query_emb = np.array(embedding_model.embed_query(query))\n",
    "\n",
    " \n",
    "\n",
    "    for q in all_web_queries:\n",
    "        for attempt in range(2):\n",
    "            try:\n",
    "                search = TavilySearchResults(max_results=2, api_key=os.environ[\"TAVILY_API_KEY\"])\n",
    "                web_results = search.invoke({\"query\": q})\n",
    "                if not isinstance(web_results, list):\n",
    "                    print(f\"⚠️ Tavily returned non-list response for query '{q}':\", web_results)\n",
    "                    continue\n",
    "                for result in web_results:\n",
    "                    if isinstance(result, dict) and \"content\" in result and \"url\" in result:\n",
    "                        content = \" \".join(result[\"content\"].split()[:800])\n",
    "                        summarized = summarize_document(content)\n",
    "                        doc = Document(page_content=summarized, metadata={\"source\": result[\"url\"]})\n",
    "                        doc_emb = np.array(embedding_model.embed_documents([summarized])[0])\n",
    "                        distance = np.linalg.norm(query_emb - doc_emb)\n",
    "                        web_docs.append((doc, distance))\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Tavily API call failed for query '{q}' (attempt {attempt+1}): {e}\")\n",
    "                if \"rate limit\" in str(e).lower():\n",
    "                    time.sleep(2)\n",
    "                else:\n",
    "                    time.sleep(1)\n",
    "\n",
    "    # --- Alpha Vantage Data ---\n",
    "    all_docs = internal_docs + web_docs\n",
    "    if av_data:\n",
    "        av_content = f\"Alpha Vantage Data for {ticker}: Price: {av_data['price']}, P/E: {av_data['pe_ratio']}, EPS: {av_data['eps']}, Revenue: {av_data['revenue']}, Market Cap: {av_data['market_cap']}\"\n",
    "        av_doc = Document(page_content=av_content, metadata={\"source\": \"Alpha Vantage\"})\n",
    "        all_docs.append((av_doc, 0.0))  # Prioritize AV data\n",
    "\n",
    "    # --- Re-Rank with Keyword Scoring ---\n",
    "    financial_keywords = [\"earnings\", \"revenue\", \"eps\", \"p/e\", \"valuation\", \"analyst\", \"rating\", \"buy\", \"sell\", \"news\"]\n",
    "    ranked_docs = []\n",
    "    for doc, score in all_docs:\n",
    "        keyword_score = sum(1 for kw in financial_keywords if kw in doc.page_content.lower())\n",
    "        adjusted_score = score - (keyword_score * 0.1)\n",
    "        ranked_docs.append((doc, adjusted_score))\n",
    "\n",
    "\n",
    "    ranked_docs_sorted = sorted(ranked_docs, key=lambda x: x[1])\n",
    "    top_docs = [doc for doc, _ in ranked_docs_sorted[:k]]\n",
    "    doc_summaries = \"\\n\".join([f\"Source: {doc.metadata.get('source', 'Company DB')}\\n{doc.page_content[:100]}...\" for doc in top_docs])\n",
    "    return top_docs, all_web_queries, doc_summaries\n",
    "\n",
    "retrieve_docs_lambda = RunnableLambda(\n",
    "\n",
    "    lambda inputs: retrieve_docs_with_fusion(inputs[\"query\"], inputs[\"ticker\"], inputs[\"av_data\"], k=3)\n",
    "\n",
    ")\n",
    "# --- Summarize Document ---\n",
    "def summarize_document(content: str) -> str:\n",
    "    prompt = summarize_prompt.format(document=content)\n",
    "    summary = llm.invoke(prompt).content.strip()\n",
    "    return \" \".join(summary.split()[:200])\n",
    "\n",
    "summarize_document_lambda = RunnableLambda(summarize_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01bceb61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T09:03:10.411064Z",
     "start_time": "2025-04-21T09:03:10.405928Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Final RAG Chain  ---\n",
    "class FusionRAG:\n",
    "    def __init__(self, llm, vectorstore, docs_per_query=3):\n",
    "        self.llm = llm\n",
    "        self.vectorstore = vectorstore\n",
    "        self.docs_per_query = docs_per_query\n",
    "        self.ticker_map = build_ticker_map(vectorstore)\n",
    "        # Define the RAG pipeline as a RunnableSequence\n",
    "\n",
    "        self.pipeline = RunnableSequence(\n",
    "\n",
    "            # Step 1: Extract ticker\n",
    "\n",
    "            lambda inputs: {\n",
    "\n",
    "                **inputs,\n",
    "\n",
    "                \"ticker\": extract_ticker_lambda.invoke({\n",
    "\n",
    "                    \"query\": inputs[\"query\"],\n",
    "\n",
    "                    \"vectorstore\": self.vectorstore,\n",
    "\n",
    "                    \"ticker_map\": self.ticker_map\n",
    "\n",
    "                })\n",
    "\n",
    "            },\n",
    "\n",
    "            # Step 2: Translate query\n",
    "\n",
    "            lambda inputs: {\n",
    "\n",
    "                **inputs,\n",
    "\n",
    "                \"translated_query\": translate_query_lambda.invoke({\n",
    "\n",
    "                    \"query\": inputs[\"query\"],\n",
    "\n",
    "                    \"ticker\": inputs[\"ticker\"]\n",
    "\n",
    "                })\n",
    "\n",
    "            },\n",
    "\n",
    "            # Step 3: Generate query variants\n",
    "\n",
    "            lambda inputs: {\n",
    "\n",
    "                **inputs,\n",
    "\n",
    "                \"query_variants\": generate_query_variants_lambda.invoke({\n",
    "\n",
    "                    \"translated_query\": inputs[\"translated_query\"]\n",
    "\n",
    "                })\n",
    "\n",
    "            },\n",
    "\n",
    "            # Step 4: Fetch Alpha Vantage data\n",
    "\n",
    "            lambda inputs: {\n",
    "\n",
    "                **inputs,\n",
    "\n",
    "                \"av_data\": fetch_alpha_vantage_lambda.invoke({\n",
    "\n",
    "                    \"ticker\": inputs[\"ticker\"]\n",
    "\n",
    "                })\n",
    "\n",
    "            },\n",
    "\n",
    "            # Step 5: Retrieve documents\n",
    "\n",
    "            lambda inputs: {\n",
    "\n",
    "                **inputs,\n",
    "\n",
    "                \"docs\": retrieve_docs_lambda.invoke({\n",
    "\n",
    "                    \"query\": inputs[\"query\"],\n",
    "\n",
    "                    \"ticker\": inputs[\"ticker\"],\n",
    "\n",
    "                    \"av_data\": inputs[\"av_data\"]\n",
    "\n",
    "                })[0],\n",
    "\n",
    "                \"query_variants\": retrieve_docs_lambda.invoke({\n",
    "\n",
    "                    \"query\": inputs[\"query\"],\n",
    "\n",
    "                    \"ticker\": inputs[\"ticker\"],\n",
    "\n",
    "                    \"av_data\": inputs[\"av_data\"]\n",
    "\n",
    "                })[1],\n",
    "\n",
    "                \"doc_summaries\": retrieve_docs_lambda.invoke({\n",
    "\n",
    "                    \"query\": inputs[\"query\"],\n",
    "\n",
    "                    \"ticker\": inputs[\"ticker\"],\n",
    "\n",
    "                    \"av_data\": inputs[\"av_data\"]\n",
    "\n",
    "                })[2]\n",
    "\n",
    "            },\n",
    "\n",
    "            # Step 6: Generate final answer\n",
    "\n",
    "            lambda inputs: {\n",
    "\n",
    "                \"result\": self.llm.invoke(qa_prompt.format(\n",
    "\n",
    "                    context=\"\\n\\n\".join([f\"Source: {'Web' if 'source' in doc.metadata else 'Company DB'}\\n{doc.page_content}\" for doc in inputs[\"docs\"]]),\n",
    "\n",
    "                    query_variants=str(inputs[\"query_variants\"]),\n",
    "\n",
    "                    doc_summaries=inputs[\"doc_summaries\"],\n",
    "\n",
    "                    question=inputs[\"query\"]\n",
    "\n",
    "                )).content.strip(),\n",
    "\n",
    "                \"query_variants\": inputs[\"query_variants\"],\n",
    "\n",
    "                \"doc_summaries\": inputs[\"doc_summaries\"]\n",
    "\n",
    "            }\n",
    "\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    def invoke(self, inputs: Dict[str, str]) -> Dict[str, str]:\n",
    "        query = inputs[\"query\"]\n",
    "        result = self.pipeline.invoke({\"query\": query})\n",
    "\n",
    "        # Log final response to LangSmith dataset\n",
    "        dataset_name = \"StockRAG\"\n",
    "        # Check if dataset exists and get its UUID\n",
    "        existing_datasets = ls_client.list_datasets()\n",
    "        dataset_id = None\n",
    "        for dataset in existing_datasets:\n",
    "            if dataset.name == dataset_name:\n",
    "                dataset_id = dataset.id\n",
    "                break\n",
    "        if dataset_id is None:\n",
    "            # Create dataset and get its UUID\n",
    "            dataset = ls_client.create_dataset(dataset_name=dataset_name)\n",
    "            dataset_id = dataset.id\n",
    "        ls_client.create_examples(\n",
    "            dataset_id=dataset_id,\n",
    "            inputs=[{\"query\": query}],\n",
    "            outputs=[{\"answer\": result[\"result\"]}]\n",
    "        )\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4747e347",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T09:04:06.622199Z",
     "start_time": "2025-04-21T09:03:10.413122Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "💬 Answer:\n",
      " Based on the provided data and summaries, here is a fundamental analysis of SMCI:\n",
      "\n",
      "**Valuation:** SMCI's current market price is $31.505, with a P/E ratio of 13.7 and EPS of $2.3 (Alpha Vantage). According to one analysis, the intrinsic value of SMCI is $44.635, suggesting that the stock is undervalued (Web).\n",
      "\n",
      "**Revenue Growth:** Analysts expect 70% revenue growth in fiscal year 2025, reaching $25 billion in revenue, and 20-25% growth in fiscal year 2026 (Web).\n",
      "\n",
      "**Earnings Growth:** EPS is expected to grow by 48% in fiscal year 2025, reaching $2.97, and continue to grow in fiscal year 2026 (Web).\n",
      "\n",
      "**Financial Health:** SMCI's financial health appears strong, with a debt-to-equity ratio of 0.40 and a gross profit margin of 14% (Web).\n",
      "\n",
      "**Analyst Recommendations:** The analysis implies a \"Buy\" recommendation, as the intrinsic value is higher than the current market price, suggesting that the stock has upside potential (Web).\n",
      "\n",
      "Overall, SMCI's financial statements indicate strong revenue and earnings growth, a low P/E ratio, and a strong financial health. These factors, combined with the analyst recommendations, suggest that SMCI is an attractive investment opportunity.\n",
      "\n",
      "Sources:\n",
      "\n",
      "* Alpha Vantage\n",
      "* Web (https://www.alphaspread.com/security/nasdaq/smci/summary)\n",
      "* Web (https://www.forbes.com/sites/investor-hub/article/super-micro-computer-smci-stock-2025-forecast/)\n"
     ]
    }
   ],
   "source": [
    "# --- Run ---\n",
    "qa_chain = FusionRAG(llm=llm, vectorstore=vectorstore)\n",
    "query = \"Fundamental Analysis of SMCI\"\n",
    "response = qa_chain.invoke({\"query\": query})\n",
    "print(\"\\n💬 Answer:\\n\", response[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bf87bca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T09:05:04.685530Z",
     "start_time": "2025-04-21T09:04:06.631269Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "💬 Answer:\n",
      " According to the Company DB, Amazon.com, Inc. (AMZN) is a multifaceted company that engages in various business activities. Here's a detailed breakdown of what Amazon does:\n",
      "\n",
      "1. **Retail Sale of Consumer Products**: Amazon sells a wide range of consumer products through its online and physical stores in North America and internationally.\n",
      "2. **Advertising Services**: The company offers various advertising services, including sponsored ads, display, and video advertising, to help businesses reach their target audience.\n",
      "3. **Subscriptions Services**: Amazon provides subscription-based services, such as Amazon Prime, which offers benefits like free shipping, streaming of music and video content, and other perks.\n",
      "4. **Manufacturing and Sales of Electronic Devices**: Amazon designs, manufactures, and sells electronic devices, including Kindle e-readers, Fire tablets, Fire TVs, Echo smart speakers, Ring doorbells, Blink security cameras, and Eero Wi-Fi routers.\n",
      "5. **Media Content Development and Production**: The company develops and produces media content, including original TV shows and movies, through its Amazon Studios division.\n",
      "6. **E-commerce Platform for Third-Party Sellers**: Amazon allows third-party sellers to sell their products on its platform, providing them with access to a vast customer base.\n",
      "7. **Cloud Computing Services**: Through its Amazon Web Services (AWS) segment, the company offers a range of cloud computing services, including compute, storage, database, analytics, machine learning, and more, to businesses, governments, and individuals.\n",
      "8. **Programs for Content Creators**: Amazon provides programs for authors, independent publishers, musicians, filmmakers, Twitch streamers, skill and app developers, and others to publish and sell their content.\n",
      "\n",
      "Overall, Amazon is a diversified company that operates in multiple segments, including retail, advertising, subscriptions, manufacturing, media content, e-commerce, and cloud computing. (Source: Company DB)\n"
     ]
    }
   ],
   "source": [
    "query = \"What does Amazon do? give detailed answer\"\n",
    "response = qa_chain.invoke({\"query\": query})\n",
    "print(\"\\n💬 Answer:\\n\", response[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc6e2d92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T09:05:04.699039Z",
     "start_time": "2025-04-21T09:05:04.690270Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# def retrieve_docs_internal_db(query, k=3):\n",
    "#     return vectorstore.similarity_search(query, k=k)\n",
    "\n",
    "\n",
    "# def rag_answer(query):\n",
    "#     docs = retrieve_docs_internal_db(query)\n",
    "#     prompt = format_prompt(docs, query)\n",
    "#     response = llm.invoke(prompt)\n",
    "#     return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ed07d45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T09:05:04.725318Z",
     "start_time": "2025-04-21T09:05:04.711106Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# from typing import List, Dict, Tuple\n",
    "# from collections import defaultdict\n",
    "# import numpy as np\n",
    "# import requests\n",
    "# from langchain_community.vectorstores import Chroma\n",
    "# from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "# from langchain_groq import ChatGroq\n",
    "# from langchain.prompts import PromptTemplate\n",
    "# from langchain.schema import Document\n",
    "# from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "# from sentence_transformers import CrossEncoder\n",
    "\n",
    "# # --- Environment Variables ---\n",
    "# # os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "# # os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "# # os.environ[\"LANGCHAIN_API_KEY\"] = \"your-langsmith-key\"\n",
    "# # os.environ[\"LANGCHAIN_PROJECT\"] = \"your-project-name\"\n",
    "# # os.environ[\"TAVILY_API_KEY\"] = \"your-tavily-api-key\"\n",
    "# os.environ[\"ALPHA_VANTAGE_API_KEY\"] = \"FP9PA5A2IF03ZK6Y\"\n",
    "\n",
    "# # --- Embeddings + Vector DB ---\n",
    "# embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "# vectorstore = Chroma(persist_directory=\"company_vectors\", embedding_function=embedding_model)\n",
    "\n",
    "# # --- Cross-Encoder for Re-Ranking ---\n",
    "# cross_encoder = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
    "\n",
    "# # --- LLM Setup ---\n",
    "# # llm = ChatGroq(\n",
    "# #     model=\"llama3-70b-8192\",\n",
    "# #     temperature=0,\n",
    "# #     groq_api_key=\"your-groq-api-key\"\n",
    "# # )\n",
    "\n",
    "# # --- Prompt Templates ---\n",
    "# qa_prompt = PromptTemplate.from_template(\"\"\"\n",
    "# You are a financial assistant. Based on the following information, which includes company data and web sources, provide a detailed fundamental analysis for the user's question, including key metrics (e.g., P/E, EPS, revenue growth, debt-to-equity) and a buy/sell recommendation if requested. Cite sources (Company DB, Web, or Alpha Vantage) where relevant. If data is limited, provide a general analysis based on available information.\n",
    "\n",
    "# Context:\n",
    "# {context}\n",
    "\n",
    "# Question: {question}\n",
    "# Answer:\n",
    "# \"\"\")\n",
    "\n",
    "# summarize_prompt = PromptTemplate.from_template(\"\"\"\n",
    "# Summarize the following financial document to ~200 words, focusing on key fundamental metrics (e.g., P/E, EPS, revenue, debt-to-equity) and analyst recommendations:\n",
    "\n",
    "# {document}\n",
    "# Summary:\n",
    "# \"\"\")\n",
    "\n",
    "# classify_prompt = PromptTemplate.from_template(\"\"\"\n",
    "# Classify the intent of this financial query as one of: 'fundamental_analysis', 'company_overview', 'news', 'technical_analysis', or 'other'. Return only the intent label.\n",
    "\n",
    "# Query: {query}\n",
    "# \"\"\")\n",
    "\n",
    "# # --- Query Rewriting ---\n",
    "# def translate_query(query: str) -> str:\n",
    "#     prompt = f\"Rewrite this stock-related query to improve document retrieval, focusing on financial metrics and analysis:\\n\\n\\\"{query}\\\"\"\n",
    "#     return llm.invoke(prompt).content.strip()\n",
    "\n",
    "# # --- Multi-query Generation ---\n",
    "# def generate_query_variants(query: str, n=2) -> List[str]:\n",
    "#     prompt = f\"Generate {n} alternative phrasings for this financial query, emphasizing fundamental analysis:\\n\\n\\\"{query}\\\"\"\n",
    "#     raw = llm.invoke(prompt).content\n",
    "#     return [line.strip(\"-• \").strip() for line in raw.split(\"\\n\") if line.strip()][:n]\n",
    "\n",
    "# # --- Query Classification ---\n",
    "# def classify_query_intent(query: str) -> str:\n",
    "#     prompt = classify_prompt.format(query=query)\n",
    "#     return llm.invoke(prompt).content.strip()\n",
    "\n",
    "# # --- Fetch Alpha Vantage Data ---\n",
    "# def fetch_alpha_vantage_data(ticker: str) -> str:\n",
    "#     url = f\"https://www.alphavantage.co/query?function=OVERVIEW&symbol={ticker}&apikey={os.environ['ALPHA_VANTAGE_API_KEY']}\"\n",
    "#     try:\n",
    "#         response = requests.get(url)\n",
    "#         data = response.json()\n",
    "#         if \"Symbol\" not in data:\n",
    "#             return \"\"\n",
    "#         metrics = (\n",
    "#             f\"Ticker: {data['Symbol']}\\n\"\n",
    "#             f\"P/E Ratio: {data.get('PERatio', 'N/A')}\\n\"\n",
    "#             f\"EPS: {data.get('EPS', 'N/A')}\\n\"\n",
    "#             f\"Revenue (TTM): {data.get('RevenueTTM', 'N/A')}\\n\"\n",
    "#             f\"Debt-to-Equity: {data.get('DebtToEquity', 'N/A')}\\n\"\n",
    "#             f\"Market Cap: {data.get('MarketCapitalization', 'N/A')}\\n\"\n",
    "#             f\"Analyst Target Price: {data.get('AnalystTargetPrice', 'N/A')}\"\n",
    "#         )\n",
    "#         return metrics\n",
    "#     except:\n",
    "#         return \"\"\n",
    "\n",
    "# # --- Summarize Document ---\n",
    "# def summarize_document(content: str) -> str:\n",
    "#     prompt = summarize_prompt.format(document=content)\n",
    "#     summary = llm.invoke(prompt).content.strip()\n",
    "#     return \" \".join(summary.split()[:200])  # Ensure ~200 words\n",
    "\n",
    "# # --- Adaptive Retrieval with Fusion, Web Search, and Re-Ranking ---\n",
    "# def retrieve_docs_with_fusion(query: str, ticker: str = \"TSLA\", k=5) -> List[Document]:\n",
    "#     intent = classify_query_intent(query)\n",
    "#     docs = []\n",
    "\n",
    "#     # Internal retrieval with fusion\n",
    "#     translated = translate_query(query)\n",
    "#     variants = generate_query_variants(translated, n=2)\n",
    "#     all_queries = [query, translated] + variants\n",
    "#     doc_scores_internal = defaultdict(list)\n",
    "#     doc_objects_internal = {}\n",
    "#     for q in all_queries:\n",
    "#         results: List[Tuple[Document, float]] = vectorstore.similarity_search_with_score(q, k=k)\n",
    "#         for doc, score in results:\n",
    "#             key = doc.metadata.get(\"ticker\", doc.page_content[:50])\n",
    "#             doc_scores_internal[key].append(score)\n",
    "#             doc_objects_internal[key] = doc\n",
    "#     internal_docs = [(doc_objects_internal[key], sum(scores) / len(scores)) for key, scores in doc_scores_internal.items()]\n",
    "\n",
    "#     # Web search and Alpha Vantage for fundamental analysis or news\n",
    "#     if intent in [\"fundamental_analysis\", \"news\", \"technical_analysis\"]:\n",
    "#         # Tavily search\n",
    "#         search = TavilySearchResults(max_results=k)\n",
    "#         web_query = f\"{ticker} {intent.replace('_', ' ')} 2025\"\n",
    "#         web_results = search.invoke({\"query\": web_query})\n",
    "#         query_emb = np.array(embedding_model.embed_query(query))\n",
    "#         web_docs = []\n",
    "#         for result in web_results:\n",
    "#             content = \" \".join(result[\"content\"].split()[:800])\n",
    "#             summarized = summarize_document(content)\n",
    "#             doc = Document(page_content=summarized, metadata={\"source\": result[\"url\"]})\n",
    "#             doc_emb = np.array(embedding_model.embed_documents([summarized])[0])\n",
    "#             distance = np.linalg.norm(query_emb - doc_emb)\n",
    "#             web_docs.append((doc, distance))\n",
    "\n",
    "#         # Alpha Vantage data\n",
    "#         av_data = fetch_alpha_vantage_data(ticker)\n",
    "#         if av_data:\n",
    "#             summarized = summarize_document(av_data)\n",
    "#             doc = Document(page_content=summarized, metadata={\"source\": \"Alpha Vantage\"})\n",
    "#             doc_emb = np.array(embedding_model.embed_documents([summarized])[0])\n",
    "#             distance = np.linalg.norm(query_emb - doc_emb)\n",
    "#             web_docs.append((doc, distance))\n",
    "\n",
    "#         docs.extend(web_docs)\n",
    "\n",
    "#     # Combine internal and web docs\n",
    "#     docs.extend(internal_docs)\n",
    "#     if not docs:\n",
    "#         return []\n",
    "\n",
    "#     # Re-rank with cross-encoder\n",
    "#     query_doc_pairs = [(query, doc[0].page_content) for doc in docs]\n",
    "#     scores = cross_encoder.predict(query_doc_pairs)\n",
    "#     ranked_docs = sorted(zip([doc[0] for doc in docs], scores), key=lambda x: x[1], reverse=True)\n",
    "#     top_docs = [doc for doc, _ in ranked_docs[:k]]\n",
    "#     return top_docs\n",
    "\n",
    "# # --- Final RAG Answer Generator ---\n",
    "# class FusionRAG:\n",
    "#     def __init__(self, llm, docs_per_query=5):\n",
    "#         self.llm = llm\n",
    "#         self.docs_per_query = docs_per_query\n",
    "\n",
    "#     def invoke(self, inputs: Dict[str, str]) -> Dict[str, str]:\n",
    "#         query = inputs[\"query\"]\n",
    "#         ticker = \"TSLA\"  # Hardcoded for Tesla; modify for dynamic ticker extraction\n",
    "#         docs = retrieve_docs_with_fusion(query, ticker, k=self.docs_per_query)\n",
    "#         if not docs:\n",
    "#             fallback_prompt = qa_prompt.format(context=\"No specific financial data retrieved.\", question=query)\n",
    "#             result = self.llm.invoke(fallback_prompt).content.strip()\n",
    "#             return {\"result\": result}\n",
    "#         context = \"\\n\\n\".join([f\"Source: {'Web' if 'source' in doc.metadata else 'Company DB'}\\n{doc.page_content}\" for doc in docs])\n",
    "#         prompt = qa_prompt.format(context=context, question=query)\n",
    "#         result = self.llm.invoke(prompt).content.strip()\n",
    "#         return {\"result\": result}\n",
    "\n",
    "# # --- Run Example ---\n",
    "# qa_chain = FusionRAG(llm=llm)\n",
    "# query = \"Can you give Tesla's fundamental analysis. Is it a buy\"\n",
    "# response = qa_chain.invoke({\"query\": query})\n",
    "# print(\"\\n💬 Answer:\\n\", response[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65b687db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T09:05:04.733956Z",
     "start_time": "2025-04-21T09:05:04.728940Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # --- Run Example ---\n",
    "# qa_chain = FusionRAG(llm=llm)\n",
    "# query = \"can you fetch the 10-year P/E ratio for Tesla.\"\n",
    "# response = qa_chain.invoke({\"query\": query})\n",
    "# print(\"\\n💬 Answer:\\n\", response[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb033ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T12:03:33.340485Z",
     "start_time": "2025-04-20T12:03:16.531439Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0cfc7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
